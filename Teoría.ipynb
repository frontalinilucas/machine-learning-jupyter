{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stocastic gradient descent\n",
    "- Dividir el lote completo en varios lotes pequeños, para que sea mas performante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Epoch\n",
    "- Cada paso en que desciende hasta encontrar el mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Batch-size\n",
    "- Tamaño del batch. Utilizar entre 32 y 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### learning_rate\n",
    "- (El hiperparámetro mas importante) Tamaño de los pasos para llegar al mínimo. Ese hiperparámetro mejora la velocidad, pero no el entrenamiento.\n",
    "- Al principio mas grande y a medida que avanza ir disminuyendo (Learning rate Decay). Debe variar en forma logarítmica => 0.1 0.01 0.001 0.0001 0.00001. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropout\n",
    "- En cada epoch de entrenamiento, cada nodo tiene un X porcentaje de no participar del entrenamiento de ese epoch. (Algunos enviamos 0 y otros enviamos el valor multiplicado x2). Así evitamos que se entren de memoria los datos de entrenamiento, es decir evitamos el overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary crossentropy\n",
    "- Redes neuronales multilabel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical crossentropy\n",
    "- Redes neuronales con una sola salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Capas convolucionales\n",
    "- Detectan patrones regionales en una imagen.\n",
    "- Aumentan la profundidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Pooling Layer (Capas de agrupación): \n",
    "- Reducen la dimensionalidad de las matrices.\n",
    "- Disminuyen el tamaño de la matriz.\n",
    "    - Pooling Layer: Reduce las matrices de entrada en aproximadamente la mitad (depende del tamaño de la ventana y del salto). Agarra una parte de la matriz de entrada (correspondiente a la ventana) y se queda con el nodo mas grande, luego realiza el “salto” y vuelve a repetir lo mismo, quedando así una matriz mucho mas pequeña.\n",
    "    - Global Pooling Layer: Reduce mas drasticamente las matrices de entrada en un vector, para hacer esto agarra cada matriz y le realiza el promedio, quedándose con un solo valor por cada matriz; es por esto que queda un vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transfer Learning\n",
    "- Una red entrenada para un set de imágenes, usarla para entrenar otro set de imágenes. Esto se puede hacer ya que las primeras capas se utilizan para entrenar patrones mas genéricos (Lineas rectas, figuras geométricas, etc) y estas se mantienen, mientras que las capas mas avanzadas se utilizan para entrenar patrones mas específicos, y estas son las que se quitan y re-entrenan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Redes conocidas:\n",
    "- AlexNet\n",
    "- VGG 16\n",
    "- VGG 19\n",
    "- ResNet\n",
    "- InceptionV3\n",
    "- Xception"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
